#website [Gary Marcus | LinkedIn](https://www.linkedin.com/in/gary-marcus-b6384b4/)
#selfdescription Gary Marcus is a scientist, best-selling author, and entrepreneur, well-known as one of the most influential voices in AI. He was the founder and CEO of Geometric Intelligence, a machine-learning company acquired by Uber in 2016, and is Founder and Executive Chairman of Robust AI. He is the author of five books, including The Algebraic Mind, Kluge, The Birth of the Mind, and The New York Times bestseller Guitar Zero, and his most recent, co-authored with Ernest Davis, Rebooting AI, one of Forbes 7 Must-Read books in AI
#post [Marc_9781524748258_2p_all_r1.s.indd (nyu.edu)](https://cs.nyu.edu/~davise/Rebooting/Chapter4.pdf)
	#thesis "Despite machine response to the question can be very convincing, it is not an answer to the question, but a mere imitation."
	#research_question Can we use existing AI architectures to build stable AI that can really substitute humans in reading and comprehension?
	#research_question What are the impediments to the machine comprehension using current architectures?
	#research_question What could be grant guidelines for AI-applications, so we won't spend resources on low-perspective projects?
	#role [[AI semantics engineer]]	#corresponds [[Project manager]]
	#concept [[*Language understanding]] #corresponds  [[Model of situation]]
		#concept [[*Mental representation]] #corresponds  [[Formal representation]]
			#concept [[*Object file]] #corresponds  [[Object]]
		#concept [[*The universe of questions and answers]] #corresponds  [[Universe of discourse]]
		#concept [[*Dialogue]] #corresponds  [[Organizational interface]] [[Domain]]
			#concept [[*Dynamic text comprehension]] #corresponds  [[Model of situation]] [[Domain model]]
				#concept [[*Chain of reasoning]] #corresponds  [[Chains and circles of communication]] [[Causal inference]]
				#concept [[*General knowledge]] #corresponds  [[Domain model]]
					#concept [[*Real-world understanding]] #corresponds  [[Latticework of mental models]]
			#concept [[*Synthesized information]] #corresponds  [[Causal inference]] [[Token-causality]]
				#concept [[*Answer]] #corresponds  [[Possible world#Types of reasoning]]
					#concept [[*Compositionality]] a way of constructing the meaning a way of constructing the meaning. #corresponds [[Modularity of definitions]] [[Text architecture, Narrative]]
				#concept [[*Cognitive model of the text]] #corresponds  [[Situational awareness]]
						#concept [[*Cognitive model of the story]]
			#concept [[*Question about the text]]
	#concept [[*End-to-end systems]]
		#concept [[*Training set]]
		#concept [[*The distance to the training set]]
		#concept [[*Unstructured text]]
		#concept [[*Taxonomy]]
		#concept [[*Deep learning feature]] an isolated bits of information without any structure.
		#concept [[*Static label]]	
#post [Don’t trust AI until we build systems that earn trust | The Economist](https://www.economist.com/open-future/2019/12/18/dont-trust-ai-until-we-build-systems-that-earn-trust)
	#thesis The engineering of large-scale AI solutions should be regulated before we can put much trust into them.
	#research_question 
	#role 
	#concept [[*Pattern-matching]]
	#concept [[*Abstractions from the text]]
	#concept [[*Real-world understanding]]
	#aspect [[*Resiliency engineering of AI]] #corresponds [[Risk]] [[Risk management]] [[Risk assessment]] [[Product]] [[Normal accidents]]  
	#aspect [[*Trustworthy AI]]  #corresponds  [[TRL]] [[Compliance]] [[Governance]] [[Trust]] [[Trust architecture]] [[Concept of product scalability]]
	#aspect  [[*Trustworthy AI]]  #corresponds [[Context]] [[Metacontext]] [[Situational awareness]] [[Model of situation]]
	#aspect [[*Explainable AI]] #corresponds [[Garbage can decision model]] [[Latticework of mental models]] [[Formal representation]]
#backlog
	#post [(1) AI's hardest problem? Developing common sense | LinkedIn](https://www.linkedin.com/pulse/ais-hardest-problem-developing-common-sense-gary-marcus/?published=t)
	#post [If Computers Are So Smart, How Come They Can’t Read? | WIRED](https://www.wired.com/story/adaptation-if-computers-are-so-smart-how-come-they-cant-read/)
	#post [Six questions to ask yourself when reading about AI (qz.com)](https://qz.com/1706248/six-questions-to-ask-yourself-when-reading-about-ai)
	#post [AGI Debate - YouTube](https://www.youtube.com/watch?v=JGiLz_Jx9uI&t=3264s)
	#post A Blunt Warning AI systems like LamDA and GPT-3 are sociopathic liars* with utter indifference to truth, deepfakers with words, every day creating more compelling, more plausible misinformation on demand. It is imperative that we develop technology & policy to thwart them.  strictly speaking they don’t lie, because they are merely statistical approximators with no regard for truth, but the effect is the same.
		#comment With an utter disregard for truth, perhaps a better condemnation would be to paint them as Franfurtian Bullshitters?
			I have, see GPT-3 Bloviator in Tech Review
		#comment C'mon Gary. How about, "Writers like Stephen King and Michael Crichton are sociopathic liars with utter indifference to truth, deepfakers with words, every day creating more compelling, more plausible misinformation on demand.."
			imagine having michael crichton writing propaganda for you, on demand
			Big difference between novels and search engines, chat bots for corps, healthcare info, etc. It's useful R&D for incremental advancement, but lacks sufficient rigor for most real-world apps. For example, in our system architecture, we compartmentalize algorithms for specific uses.
			The noise is almost entirely for the purpose of creating hype to continue and expand funding, attempt to convince the world that their lab is top dog, and increase career opps for those practicing hyperbole.
			It's interesting to me, but I am aware of the limitations. That's not true for the supermajority of targets - media, investors, govts, students, and in some cases corp overlords.
			Look at how the relationships are structured. In DeepMind Google owns it outright but impression is promoted that it's an autonomous research org. It isn't.
			In the case of OpenAI Microsoft has it zipped up pretty tight, but the impression is that it's an independent firm. Not really - funding is from Microsoft and they have an exclusive AG requiring Azure, which limits competition. Both are businesses.
			And then there is FB... why anyone would take FB seriously is mind boggling.
	#post [Is ChatGPT Really a “Code Red” for Google Search? (substack.com)](https://garymarcus.substack.com/p/is-chatgpt-really-a-code-red-for)
		#comment What do you see as the actual “phenomenal” commercial applications of large language models? Codex seems viable; I have my doubts as to whether search can made reliable enough to displace Google.
			This. As someone who has worked putting these models into production for over three years - the science is still out as whether current approaches can really yield reliability. Try to fully automate any business function and you’ll see first-hand. Great for inspiration though; and great fun.
	#post https://www.linkedin.com/posts/gary-marcus-b6384b4_in-many-ways-my-favorite-moment-in-any-interview-activity-7018481538384240640-Stbm?utm_source=share&utm_medium=member_desktop
		#comment  Hi Gary, I'm a huge fan of yours having read some of your books and watched some of your interviews. The GPT model, while not built up with reasoning and logic, can be surprisingly plausible for humans (perhaps too plausible and confident). Does this mean that human thinking is not as logical and filled with reasoning as we think we have? Also, what do you think are the prospects of using GPT to power search? I think that generating the search results directly from prompts is a bad approach (lots of factually wrong results appear). How about using GPT as a CLIP-like objective to rank webpages based on the query? Maybe the log probabilities of the tokenized text of the webpage can be used to rank them.
			thanks! I have serious doubts about GPTChat as search: [https://garymarcus.substack.com/p/is-chatgpt-really-a-code-red-for](https://garymarcus.substack.com/p/is-chatgpt-really-a-code-red-for)